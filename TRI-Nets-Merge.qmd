---
title: "TRI-Nets-Merge"
author: "Jeffrey Wu"
date: "2024-10-21"
output: html_document
---

```{r}
library(readxl)
library(dplyr)
library(tidyverse)
```

Load Easy RSEI data (hazard and estimated total releases in pounds)

```{r}
# RSEI_data1 = read_excel("EasyRSEI-AllYears1.xlsx")
RSEI_data2 = read_excel("EasyRSEI-8894.xlsx")
# RSEI_data3 = read_excel("EasyRSEI-AllYears3.xlsx")
RSEI_data4 = read_excel("EasyRSEI-9522.xlsx")


# unique(RSEI_data1$`Submission Year`)
unique(RSEI_data2$`Submission Year`)
# unique(RSEI_data3$`Submission Year`)
unique(RSEI_data4$`Submission Year`)

RSEI_data8894 = RSEI_data2 %>% filter(`Submission Year` < 1995)
RSEI_data8822 = rbind(RSEI_data8894,RSEI_data4)

length(unique(RSEI_data8822$`TRI Facility ID`))

RSEI_data9022 = RSEI_data8822 %>% filter(`Submission Year` >= 1990)

#Make TRIFID_yr ID col and grab modeled hazard 
RSEI_data9022$TRIFID_yr = str_c(RSEI_data9022$`TRI Facility ID`,"-",RSEI_data9022$`Submission Year`)
RSEI_df = RSEI_data9022 %>% group_by(TRIFID_yr) %>% summarize(sum(total_hazard = sum(`RSEI Modeled Hazard`)))

colnames(RSEI_df) = c("TRIFID_yr","RSEI_Hazard")
```

Test whether Easy RSEI modeled pounds and modeled hazard matches Mary and Dustin's data

- Modeled pounds doesn't match TRI reported pounds released (sometimes close sometimes not)
- Modeled hazard matches their RSEI Hazard value

```{r,eval=FALSE}
CleanDataLongAllYears = read.csv("CleanDataLongAllYears.csv")

CleanDataLong2000 = CleanDataLongAllYears %>% filter(trifid_YEAR == "00603HWLTTSTATE_2010")
RSEI_test = RSEI_df %>% filter(TRIFID_yr == "00603HWLTTSTATE2010")

CleanDataLong2000$Hazard
RSEI_test$RSEI_Hazard
```

IMPORTANT FUNCTION FOR READING IN NETS FILES: 

```{r}
convert_read_txt_data = function(file_path){
  # Read the entire file
  lines <- readLines(file_path, warn = FALSE)
  
  # Convert encoding
  lines <- iconv(lines, "UTF-8", "ASCII", sub = "byte")
  
  # Write the updated lines back to the file
  writeLines(lines, file_path)
  
  # Read updated txt files into R 
  data = read_delim(file_path,delim = "\t")
  
  return(data)
}
```

Load 1989-2022 TRI data: 

```{r,echo=FALSE,eval=FALSE}
# TRI1987 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1987.txt")
# TRI1988 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1988.txt")
# TRI1989 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1989.txt")
TRI1990 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1990.txt")
TRI1991 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1991.txt")
TRI1992 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1992.txt")
TRI1993 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1993.txt")
TRI1994 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1994.txt")
TRI1995 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1995.txt")
TRI1996 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1996.txt")
TRI1997 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1997.txt")
TRI1998 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1998.txt")
TRI1999 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-1999.txt")
TRI2000 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2000.txt")
TRI2001 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2001.txt")
TRI2002 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2002.txt")
TRI2003 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2003.txt")
TRI2004 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2004.txt")
TRI2005 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2005.txt")
TRI2006 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2006.txt")
TRI2007 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2007.txt")
TRI2008 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2008.txt")
TRI2009 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2009.txt")
TRI2010 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2010.txt")
TRI2011 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2011.txt")
TRI2012 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2012.txt")
TRI2013 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2013.txt")
TRI2014 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2014.txt")
TRI2015 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2015.txt")
TRI2016 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2016.txt")
TRI2017 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2017.txt")
TRI2018 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2018.txt")
TRI2019 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2019.txt")
TRI2020 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2020.txt")
TRI2021 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2021.txt")
TRI2022 = convert_read_txt_data("C:/Users/jeffr/Desktop/Pulver TRI Paper/TRI-BasicPlus-Files/TRI-BasicPlus-2022.txt")

# problems(TRI2000)
# spec(TRI2000)
# colnames(TRI2000)

# colnames(TRI1988) = colnames(TRI1987)
# colnames(TRI1989) = colnames(TRI1987)
colnames(TRI1990) = colnames(TRI1987)
colnames(TRI1991) = colnames(TRI1987)
colnames(TRI1992) = colnames(TRI1987)
colnames(TRI1993) = colnames(TRI1987)
colnames(TRI1994) = colnames(TRI1987)
colnames(TRI1995) = colnames(TRI1987)
colnames(TRI1996) = colnames(TRI1987)
colnames(TRI1997) = colnames(TRI1987)
colnames(TRI1998) = colnames(TRI1987)
colnames(TRI1999) = colnames(TRI1987)
colnames(TRI2000) = colnames(TRI1987)
colnames(TRI2001) = colnames(TRI1987)
colnames(TRI2002) = colnames(TRI1987)
colnames(TRI2003) = colnames(TRI1987)
colnames(TRI2004) = colnames(TRI1987)
colnames(TRI2005) = colnames(TRI1987)
colnames(TRI2006) = colnames(TRI1987)
colnames(TRI2007) = colnames(TRI1987)
colnames(TRI2008) = colnames(TRI1987)
colnames(TRI2009) = colnames(TRI1987)
colnames(TRI2010) = colnames(TRI1987)
colnames(TRI2011) = colnames(TRI1987)
colnames(TRI2012) = colnames(TRI1987)
colnames(TRI2013) = colnames(TRI1987)
colnames(TRI2014) = colnames(TRI1987)
colnames(TRI2015) = colnames(TRI1987)
colnames(TRI2016) = colnames(TRI1987)
colnames(TRI2017) = colnames(TRI1987)
colnames(TRI2018) = colnames(TRI1987)
colnames(TRI2019) = colnames(TRI1987)
colnames(TRI2020) = colnames(TRI1987)
colnames(TRI2021) = colnames(TRI1987)
colnames(TRI2022) = colnames(TRI1987)

important_TRI_cols = c(2,9:15,18,24:29,34:50,71:73,107:109,111:113,115,171,217,218,262)

# TRIdata_raw = rbind(TRI1987[,important_TRI_cols],TRI1988[,important_TRI_cols],TRI1989[,important_TRI_cols],
#                     TRI1990[,important_TRI_cols],TRI1991[,important_TRI_cols],TRI1992[,important_TRI_cols],
#                     TRI1993[,important_TRI_cols],TRI1994[,important_TRI_cols],TRI1995[,important_TRI_cols],
#                     TRI1996[,important_TRI_cols],TRI1997[,important_TRI_cols],TRI1998[,important_TRI_cols],
#                     TRI1999[,important_TRI_cols],TRI2000[,important_TRI_cols],TRI2001[,important_TRI_cols],
#                     TRI2002[,important_TRI_cols],TRI2003[,important_TRI_cols],TRI2004[,important_TRI_cols],
#                     TRI2005[,important_TRI_cols],TRI2006[,important_TRI_cols],TRI2007[,important_TRI_cols],
#                     TRI2008[,important_TRI_cols],TRI2009[,important_TRI_cols],TRI2010[,important_TRI_cols],
#                     TRI2011[,important_TRI_cols],TRI2012[,important_TRI_cols],TRI2013[,important_TRI_cols],
#                     TRI2014[,important_TRI_cols],TRI2015[,important_TRI_cols],TRI2016[,important_TRI_cols],
#                     TRI2017[,important_TRI_cols],TRI2018[,important_TRI_cols],TRI2019[,important_TRI_cols],
#                     TRI2020[,important_TRI_cols],TRI2021[,important_TRI_cols],TRI2022[,important_TRI_cols])

TRIdata_raw = rbind(TRI1990[,important_TRI_cols],TRI1991[,important_TRI_cols],
                    TRI1992[,important_TRI_cols],TRI1993[,important_TRI_cols],
                    TRI1994[,important_TRI_cols],TRI1995[,important_TRI_cols],
                    TRI1996[,important_TRI_cols],TRI1997[,important_TRI_cols],
                    TRI1998[,important_TRI_cols],TRI1999[,important_TRI_cols],
                    TRI2000[,important_TRI_cols],
                    TRI2001[,important_TRI_cols],TRI2002[,important_TRI_cols],TRI2003[,important_TRI_cols],
                    TRI2004[,important_TRI_cols],TRI2005[,important_TRI_cols],TRI2006[,important_TRI_cols],
                    TRI2007[,important_TRI_cols],TRI2008[,important_TRI_cols],TRI2009[,important_TRI_cols],
                    TRI2010[,important_TRI_cols],TRI2011[,important_TRI_cols],TRI2012[,important_TRI_cols],
                    TRI2013[,important_TRI_cols],TRI2014[,important_TRI_cols],TRI2015[,important_TRI_cols],
                    TRI2016[,important_TRI_cols],TRI2017[,important_TRI_cols],TRI2018[,important_TRI_cols],
                    TRI2019[,important_TRI_cols],TRI2020[,important_TRI_cols],TRI2021[,important_TRI_cols],
                    TRI2022[,important_TRI_cols])

# rm(TRI1987,TRI1988,TRI1989,TRI1990,TRI1991,TRI1992,TRI1993,TRI1994,TRI1995,TRI1996,TRI1997,TRI1998,
#    TRI1999,TRI2000,TRI2001,TRI2002,TRI2003,TRI2004,TRI2005,TRI2006,TRI2007,TRI2008,TRI2009,TRI2010,
#    TRI2011,TRI2012,TRI2013,TRI2014,TRI2015,TRI2016,TRI2017,TRI2018,TRI2019,TRI2020,TRI2021,TRI2022)
```

```{r}
#Load raw TRI data
# saveRDS(TRIdata_raw, file = "rawTRIdata_8722.rds")
TRIdata_raw = readRDS(file = "rawTRIdata_8722.rds")

TRIdata_raw = TRIdata_raw[,-c(36,37,39,40)]

TRIdata_raw = TRIdata_raw %>% filter(`2. REPORTING YEAR` >= 1990)
TRIdata_raw$TRIFID_yr = str_c(TRIdata_raw$`9. TRIFD`,"-",TRIdata_raw$`2. REPORTING YEAR`)

test = TRIdata_raw %>% group_by(TRIFID_yr) %>% summarize(total_fugitive_air = sum(`109. TOTAL FUGITIVE AIR EMISSIONS`), total_stack = sum(`113. TOTAL STACK AIR EMISSIONS`), total_air = sum(`115. TOTAL AIR EMISSIONS`), total_water = sum(`171. TOTAL SURFACE WATER DISCHARGE`), total_land = sum(`217. TOTAL ON-SITE LAND RELEASES`), total_releases = sum(`218. TOTAL ON-SITE RELEASES`), total_transferred = sum(`262. TOTAL TRANSFERRED OFF SITE FOR FURTHER WASTE MANAGEMENT`))

additional_columns <- TRIdata_raw %>%
  select(-c(`109. TOTAL FUGITIVE AIR EMISSIONS`, `113. TOTAL STACK AIR EMISSIONS`, 
            `115. TOTAL AIR EMISSIONS`, `171. TOTAL SURFACE WATER DISCHARGE`, 
            `217. TOTAL ON-SITE LAND RELEASES`, `218. TOTAL ON-SITE RELEASES`, 
            `262. TOTAL TRANSFERRED OFF SITE FOR FURTHER WASTE MANAGEMENT`)) %>%
  distinct(TRIFID_yr, .keep_all = TRUE)  # Keep one row per group

TRIdata_temp <- test %>%
  left_join(additional_columns, by = "TRIFID_yr")

length(unique(TRIdata_temp$TRIFID_yr))
```



Merge RSEI and TRI data on TRIFID: 

```{r}
#More TRI facilities in TRI data than RSEI data 
length(unique(TRIdata_temp$TRIFID_yr))
length(unique(RSEI_df$TRIFID_yr))

# facility_subset = unique(RSEI_df$`9. TRIFD`)
# 
# keep_idx = c()
# 
# for (i in facility_subset){
#   keep_idx = c(keep_idx,which(TRIdata_raw$`9. TRIFD` == i))
# }
# 
# TRI_subset = TRIdata_raw[keep_idx,]

TRI_RSEI = full_join(TRIdata_temp,RSEI_df,by = "TRIFID_yr") 

TRI_RSEI$total_produced = TRI_RSEI$total_releases + TRI_RSEI$total_transferred
```

Load crosswalk for merge: 

```{r,warning=FALSE}
TRIFID_DUNS = read.table("TRI-Duns-Crosswalk22.txt",header=TRUE)
TRIFID_DUNS$DunsNumber = as.character(TRIFID_DUNS$DunsNumber)

length(unique(TRIFID_DUNS$TRIFID)) #56739 (more TRIFID IDs than Duns #?)
length(unique(TRIFID_DUNS$DunsNumber)) #54474

DUNS_with_TRIFID = unique(TRIFID_DUNS$DunsNumber)


#Make sure every DunsNumber in crosswalk has 9 numbers 
for (i in 1:length(TRIFID_DUNS$DunsNumber)){
  
  if(nchar(TRIFID_DUNS$DunsNumber[i]) < 9){
    len = nchar(TRIFID_DUNS$DunsNumber[i])
    attach = strrep(0,9-len)
    
    TRIFID_DUNS$DunsNumber[i] = str_c(attach,TRIFID_DUNS$DunsNumber[i])
  }
}

char_lens3 = nchar(TRIFID_DUNS$DunsNumber)
length(which(char_lens3 < 9))
```

Merge TRIFID_NETS crosswalk to TRI data 

```{r}
# This join only keeps facilities w TRIFID that are in crosswalk dataset (less than left join, less than raw TRI data)
TRIdata_final = inner_join(TRIFID_DUNS,TRI_RSEI,join_by(TRIFID == `9. TRIFD`))

# This join keeps all facilities in raw TRI data and joins on TRIFID for facilities in crosswalk dataset (more than inner join, more than raw TRI data)
# test2 = TRIdata_raw %>% left_join(TRIFID_DUNS,join_by(`9. TRIFD` == TRIFID))

TRIdata_final$Duns_TRIFID = str_c(TRIdata_final$DunsNumber,"-",TRIdata_final$TRIFID)
TRIdata_final$Duns_yr = str_c(TRIdata_final$DunsNumber,"-",TRIdata_final$`2. REPORTING YEAR`)
```


Investigating the facilities with DIFFERENT TRIFID but SAME DUNS #... a lot of different scenarios so leave it alone for now

```{r,eval=FALSE}
unique_dunsyrs = unique(TRIdata_final$Duns_yr)
ID1 = c()

for (i in unique_dunsyrs){
  TRI = TRIdata_final %>% filter(Duns_yr == i)
  if(nrow(TRI) > 1){
    ID1 = c(ID1,i)
  }
}

###ID1 has 13908 Duns_yrs

# subset = TRIdata2012[which(TRIdata2012$`24. ENTIRE FACILITY IND` == "NO"),]
# length(unique(subset$DunsNumber))

same_duns_locations_diff_trifid = TRIdata_final[1,]

tracker=1

for (j in ID1[1:200]){
  pull = TRIdata_final %>% filter(Duns_yr == j)
  location = str_c(pull$`47. LATITUDE`,pull$`48. LONGITUDE`)
  
  if(length(unique(location)) == 1){
    same_duns_locations_diff_trifid = rbind(same_duns_locations_diff_trifid,pull)
  }
}

same_duns_locations_diff_trifid = same_duns_locations_diff_trifid[-1,]
write.csv(same_duns_locations_diff_trifid,file="same_duns_locations_diff_trifid.csv")
```


Rows 8 and 9 have same Duns number but different TRIFID (same company but different building)

Load NETS data (columns are variables over time 1990-2022)

```{r}
DUNS_NETS = convert_read_txt_data("NETSData_TRI2022.txt")

remove_NETS_cols = c(105:148,185:218,221:286,392:402)

NETS_data = DUNS_NETS[,-remove_NETS_cols]
```


Load NAICS_TRI2022.txt data (should match dimensions of NETSData_TRI2022.txt)

```{r}
DUNS_NAICS = convert_read_txt_data("NAICS_TRI2022.txt")
```

Merge NETS and NAICS data: 

```{r}
length(unique(DUNS_NETS$DunsNumber))
length(unique(DUNS_NAICS$DunsNumber))

DUNS_df = inner_join(NETS_data,DUNS_NAICS,by="DunsNumber")
```

Why is the match rate so low between NETS data and TRIFID-NETS crosswalk?? Should be perfect? 

Turns out bc we needed to add 0's to the front of some Duns #'s so that they have chr length 9

```{r}
# which(TRIFID_DUNS$DunsNumber == "001000470")
# which(TRIFID_DUNS$DunsNumber == "001003458")

char_lens1 = nchar(NETS_data$DunsNumber)
char_lens2 = nchar(TRIFID_DUNS$DunsNumber)

length(which(char_lens2 < 9))

test = inner_join(DUNS_df,TRIFID_DUNS,by="DunsNumber")
length(unique(test$DunsNumber))
length(unique(test$TRIFID))
```


Reformat NETS data to have year as a column instead of different columns representing different observation years (first create one dataframe per year then recombine together)

```{r}
years = c(90,91,92,93,94,95,96,97,98,99,"00","01","02","03","04","05","06","07","08","09",10,11,12,
          13,14,15,16,17,18,19,20,21,22)

NETS_by_yr = list()
tracker = 1

for (i in years){
  df = DUNS_df[,c(1:35,104:106,140:142,246:267)]
  col_yrs = which(endsWith(colnames(DUNS_df),i))
  col_yrs = col_yrs[c(1,5,7)]
  
  df = cbind(df,DUNS_df[,col_yrs])
  colnames(df)[64:66] = c("Employees","Sales","NAICS")
  
  if(tracker <= 10){
    Year = str_c("19",i)
  } else{
    Year = str_c("20",i)
  }
  
  df = cbind(Year,df)
  
  
  NETS_by_yr[[tracker]] = df
  tracker = tracker+1
}

names(NETS_by_yr) = years
```

```{r}
DUNS_df_by_yr = NETS_by_yr[[1]]

for (j in 2:length(NETS_by_yr)){
  DUNS_df_by_yr = rbind(DUNS_df_by_yr,NETS_by_yr[[j]])
}

DUNS_df_by_yr = cbind(str_c(DUNS_df_by_yr$DunsNumber,"-",DUNS_df_by_yr$Year),DUNS_df_by_yr)
colnames(DUNS_df_by_yr)[1] = "Duns_yr"

# test = DUNS_df_by_yr %>% filter(DunsNumber == "001000892")
```


Merge TRI data with NETS data on Duns_yr

```{r}
TRI_NETS = inner_join(TRIdata_final,DUNS_df_by_yr,by = "Duns_yr")

length(unique(TRI_NETS$TRIFID_yr))
```

Count how many facility reports each year has: 

```{r}
yearly_facility_count = c()

for (i in 1990:2022){
  yr_data = TRI_NETS %>% filter(Year == i)
  facility_count = length(unique(yr_data$TRIFID))
  
  yearly_facility_count = c(yearly_facility_count,facility_count)
}

yearly_facility_count_df = data.frame(yr = c(1990:2022),yearly_facility_count)

barplot(height = yearly_facility_count_df$yearly_facility_count, names.arg = yearly_facility_count_df$yr)
```

Impute missing employees and sales data points bc these are important predictors: 

```{r}
emp_idx = which(is.na(TRI_NETS$Employees))
sales_idx = which(is.na(TRI_NETS$Sales))

na_idx = union(emp_idx,sales_idx)

### take median of industry not entire dataset

for (i in na_idx){
  obs = TRI_NETS[i,]
  obs_industry = obs$`41. PRIMARY NAICS CODE`
  obs_industry_data = TRI_NETS %>% filter(`41. PRIMARY NAICS CODE` == obs_industry) %>% select(Employees,Sales)
  
  past_emp_data = TRI_NETS %>% filter(TRIFID == obs$TRIFID) %>%
    select(Employees) %>% na.omit()
  past_sales_data = TRI_NETS %>% filter(TRIFID == obs$TRIFID) %>%
    select(Sales) %>% na.omit()

  if(nrow(past_emp_data) == 0){
    #if no past data, use industry median
    emp_median = median(na.omit(obs_industry_data$Employees)) 
    
    TRI_NETS$Employees[i] = emp_median
  } else{
    TRI_NETS$Employees[i] = median(past_emp_data$Employees) #use median of past reports if available
  }
  
    if(nrow(past_sales_data) == 0){
    sales_median = median(na.omit(obs_industry_data$Sales))
    
    TRI_NETS$Sales[i] = sales_median
  } else{
    TRI_NETS$Sales[i] = median(past_sales_data$Sales)
  }
}
```

Need to create new variables EmpShare and MarketShare

```{r}
TRI_NETS$NAICS_yr = str_c(TRI_NETS$`41. PRIMARY NAICS CODE`,"-",TRI_NETS$Year)
NAICS_totals = TRI_NETS %>% group_by(NAICS_yr) %>% summarize(naics_emp = sum(Employees,na.rm = FALSE),
                                                                          naics_sales = sum(Sales,na.rm = FALSE))

TRI_NETS$EmpShare = rep(NA,nrow(TRI_NETS))
TRI_NETS$MarketShare = rep(NA,nrow(TRI_NETS))

for (i in 1:nrow(TRI_NETS)){
  idx = which(NAICS_totals$NAICS_yr == TRI_NETS$NAICS_yr[i])
  
  TRI_NETS$EmpShare[i] = TRI_NETS$Employees[i] / NAICS_totals$naics_emp[idx]
  TRI_NETS$MarketShare[i] = TRI_NETS$Sales[i] / NAICS_totals$naics_sales[idx]
}
```


Save and subset data to work on offline: 

```{r}
saveRDS(TRI_NETS, file = "TRI_NETS_9022.rds")

TRI_NETS_subset = TRI_NETS %>% filter(Year > 2016)

saveRDS(TRI_NETS_subset, file = "tri-nets-subset.rds")
```



ALTERNATIVE MERGE (need to attach crosswalk so we don't use)

Merge TRIFID_NETS crosswalk to NETS data 

```{r,eval=FALSE}
DUNS_df2 = inner_join(TRIFID_DUNS,DUNS_df_by_yr,by = "DunsNumber")

DUNS_df2$Duns_TRIFID = str_c(DUNS_df2$DunsNumber,DUNS_df2$TRIFID)
DUNS_df2$TRIFID_yr = str_c(DUNS_df2$TRIFID,DUNS_df2$Year)
```

Merge TRI data with NETS data on TRIFID_yr

```{r,eval=FALSE}
TRI_NETS2 = inner_join(TRIdata_final,DUNS_df2,by = "TRIFID_yr")

# which(colnames(test) == 'Duns_TRIFID')
TRI_NETS2$Duns_TRIFID_yr = str_c(TRI_NETS2$Duns_TRIFID,TRI_NETS2$`2. REPORTING YEAR`)

length(unique(TRI_NETS2$TRIFID_yr))
```

Merge TRI data with NETS data on DunsNumber_TRIFID (prob don't need)

```{r,eval=FALSE}
TRI_NETS3 = inner_join(TRIdata_final,DUNS_df2,by = "Duns_TRIFID")

# which(colnames(test) == 'Duns_TRIFID')
TRI_NETS3$Duns_TRIFID_yr = str_c(TRI_NETS3$Duns_TRIFID,TRI_NETS3$`2. REPORTING YEAR`)
```



ATTACHING CENSUS BLOCK GROUP DATA SURROUNDING EACH FACILITY

```{r,eval=FALSE}
library(here)
library(sf)
library(tidycensus)
library(tidyverse)

# geodat90 <- readRDS("geolytics90.rds")
# geodat00 <- readRDS("geolytics00.rds")
geodat10 <- readRDS("geolytics10.rds")
geodat20 <- readRDS("geolytics20.rds")

TRI_NETS <- readRDS("TRI_NETS_9022.rds") 

### 

tri_locations <- TRI_NETS %>% select(TRIFID,`47. LATITUDE`,`48. LONGITUDE`)
tri_locations2 <- st_as_sf(tri_locations, coords = c("48. LONGITUDE","47. LATITUDE"), crs = "EPSG:4269")
tri_locations3 <- tri_locations2 %>% distinct(TRIFID, .keep_all = TRUE)

length(unique(tri_locations3$geometry)) ###shows 50k unique coordinate locations? 
tri_locations3 %>% ggplot() + geom_sf() ###plots out as well? 
```

# Query official 2020 census boundaries

```{r,eval=FALSE}
# census_api_key("dde0057a5d2c930260f04891e6369afcf4a5bd38",install = TRUE)
options(tigris_use_cache = TRUE)

state_abbreviations <- c(
  "AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", 
  "MD", "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", 
  "RI", "SC", "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY", "PR")

census20 = get_acs(geography = "block group",variables = c("population" = "B01001_001"),state = state_abbreviations,geometry = T,year = 2020) %>%
  st_transform(crs="EPSG:4269")  
```

## Merge new data set 

```{r,eval=FALSE}
geolytics20 <- as.data.frame(geodat20)
colnames(geolytics20) = c("GEOID","populationE","white_alone_popE",
                          "poverty_checkedE","pop_below_povertyE","geometry")
## one minute 
New_Coords <- census20 %>%
  left_join(geolytics20, join_by(GEOID))

censusGEOID = census20$GEOID
geolyticsGEOID = geolytics20$GEOID

overlap = intersect(censusGEOID,geolyticsGEOID)

new_geolytics20 = New_Coords[,-c(3,4,5,11)]

# Plot for good measure: THIS PLOT ONLY PLOTS ONE TRI LOCATION THOUGH??? WHERE DID THE REST GO
ggplot() +
  geom_sf(data = new_geolytics20) +
  geom_sf(data = tri_locations3, col = "orange")+
  theme_classic()
```

It appears that only one TRI location is getting carried through to the buffer-apportionment step... so the intersection is attaching the same two block groups (corresponding to the one CA facility being plotted) to each facility (even if the facility is in Alaska or Puerto Rico)

```{r,eval=FALSE}
tri_locations4 = st_transform(tri_locations3,crs="EPSG:3310")
new2_geolytics20 = st_transform(new_geolytics20,crs="EPSG:3310")

## Buffer points
tribuff <- st_buffer(tri_locations4, dist = 3*1600) %>% 
  mutate(area_buff = st_area(.)) # creates new area (should all be the same)

## Plot again for good measure:
# new_geolytics20 %>%
#   ggplot()+
#   geom_sf(aes(fill = populationE ))+
#   geom_sf(data = tribuff, col = "orange",alpha=.1)+
#   geom_sf(data = tri_locations_sample, col = "orange")+
#   theme_classic()

# Do the intersection join
jdat <- st_intersection(tribuff, new2_geolytics20) %>%
                       mutate(intersect_area = st_area(.), 
                              area_p = as.numeric(intersect_area/area_buff)) # get percentage
 
# summarize
jdat_clean <- jdat %>%
  group_by(TRIFID)%>%
  summarize(pop_apportioned = sum(area_p * populationE, 
                                  na.rm = TRUE),
            white_pop_apportioned = sum(area_p * white_alone_popE, 
                                        na.rm = TRUE),
            poverty_checked_apportioned = sum(area_p * poverty_checkedE, 
                                  na.rm = TRUE),
            below_poverty_apportioned = sum(area_p * pop_below_povertyE, 
                                  na.rm = TRUE),
            geometry = st_union(geometry)) # Or your values
```

## Plot for good measure:

```{r,eval=FALSE}
new2_geolytics20 %>%
  ggplot() + geom_sf() + 
  geom_sf(data = tribuff, col = "orange",fill = NA) +
  geom_sf(data = jdat_clean, aes(fill = pop_apportioned)) +
  theme_classic()
```

## Attach to TRI_NETS

ATTACH NEW CENSUS DATA TO ORIGINAL TRI_NETS 

```{r,eval=FALSE}
TRI_NETS_9022 = readRDS("TRI_NETS_9022.rds")

apportioned_data90 = readRDS("jdat_clean90.rds")
apportioned_data00 = readRDS("jdat_clean00.rds")
apportioned_data10 = readRDS("jdat_clean10.rds")
apportioned_data20 = readRDS("jdat_clean20.rds")

decade_data = rbind(apportioned_data90,apportioned_data00,
                    apportioned_data10,apportioned_data20)
decade_data = as.data.frame(decade_data)
decade_data = decade_data[,-6]
decade_data[,c(2:5)] = round(decade_data[,c(2:5)])

decade_data$Year = rep(c(1990,2000,2010,2020),each = 52641)
```

Interpolate non-decadal years with best fit lines in Excel -> import this dataset back and attach to TRI_NETS: 

```{r}
TRI_NETS_9022 = readRDS("TRI_NETS_9022.rds")
interpolated_census_df = read_xlsx("pulver_interpolated_census.xlsx")

# Reshape the dataframe
full_census_df = data.frame(interpolated_census_df$`TRIFID (no 1990 census data for peach cells)`,1990,0,0,0,0)
colnames(full_census_df) = c("TRIFID","Year","pop_apportioned","white_pop_apportioned",
                           "poverty_checked_apportioned","below_poverty_apportioned")
col_idx = c(3,36,69,102)
full_census_df[,3:6] = interpolated_census_df[,col_idx]

for (i in 1991:2022){
  attach_df = data.frame(interpolated_census_df$`TRIFID (no 1990 census data for peach cells)`,i)
  col_idx = col_idx + 1
  newdata = interpolated_census_df[,col_idx]
  attach_df = cbind(attach_df,newdata)
  
  colnames(attach_df) = c("TRIFID","Year","pop_apportioned","white_pop_apportioned",
                           "poverty_checked_apportioned","below_poverty_apportioned")
  full_census_df = rbind(full_census_df,attach_df)
}

# Create variables we are actually interested in

# %non white
full_census_df$prop_nonwhite = 1 - (full_census_df$white_pop_apportioned / full_census_df$pop_apportioned)

# %below poverty
full_census_df$prop_below_poverty = full_census_df$below_poverty_apportioned / full_census_df$poverty_checked_apportioned

saveRDS(full_census_df,"full_census_df_10.21.rds")
```

```{r}
full_census_df$TRIFID_yr = str_c(full_census_df$TRIFID,"-",full_census_df$Year)
TRI_NETS_9022$TRIFID_yr = str_c(TRI_NETS_9022$TRIFID,"-",TRI_NETS_9022$Year)

TRI_NETS_withcensus = TRI_NETS_9022 %>% left_join(full_census_df[,c(3:9)],by="TRIFID_yr")

saveRDS(TRI_NETS_withcensus,"TRI_NETS_withcensus_10.21.rds")
```

